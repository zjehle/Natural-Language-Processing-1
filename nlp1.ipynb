{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a temperature in celcius: 30\n",
      "86.0 F\n"
     ]
    }
   ],
   "source": [
    "def convert_celcius_to_fahrenheit(temp):\n",
    "    return (temp*(9/5))+32\n",
    "\n",
    "try:\n",
    "    temp = convert_celcius_to_fahrenheit(float(input(\"Enter a temperature in celcius: \")))\n",
    "    print(temp,'F')\n",
    "except Exception:\n",
    "    print(\"please enter a valid number\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#path_to_grade_file = \"\"\n",
    "#grades = pd.read_csv(path_to_grade_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102  25  23  46]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([100,5,20,6])\n",
    "b = np.array([2,20,3,40])\n",
    "c = a+b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/zacharyjehle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Call me Ishmael. Some years ago — never mind how long precisely — having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world. It is a way I have of driving off the spleen, and regulating the circulation. Whenever I find myself growing grim about the mouth; whenever it is a damp, drizzly November in my soul; whenever I find myself involuntarily pausing before coffin warehouses, and bringing up the rear of every funeral I meet; and especially whenever my hypos get such an upper hand of me, that it requires a strong moral principle to prevent me from deliberately stepping into the street, and methodically knocking people's hats off — then, I account it high time to get to sea as soon as I can. This is my substitute for pistol and ball. With a philosophical flourish Cato throws himself upon his sword; I quietly take to the ship. There is nothing surprising in this. If they but knew it, almost all men in their degree, some time or other, cherish very nearly the same feelings towards the ocean with me.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import nltk \n",
    "nltk.download(\"punkt\")\n",
    "tokens = nltk.word_tokenize(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael', '.', 'Some', 'years', 'ago', '—', 'never', 'mind', 'how', 'long', 'precisely', '—', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '.', 'It', 'is', 'a', 'way', 'I', 'have', 'of', 'driving', 'off', 'the', 'spleen', ',', 'and', 'regulating', 'the', 'circulation', '.', 'Whenever', 'I', 'find', 'myself', 'growing', 'grim', 'about', 'the', 'mouth', ';', 'whenever', 'it', 'is', 'a', 'damp', ',', 'drizzly', 'November', 'in', 'my', 'soul', ';', 'whenever', 'I', 'find', 'myself', 'involuntarily', 'pausing', 'before', 'coffin', 'warehouses', ',', 'and', 'bringing', 'up', 'the', 'rear', 'of', 'every', 'funeral', 'I', 'meet', ';', 'and', 'especially', 'whenever', 'my', 'hypos', 'get', 'such', 'an', 'upper', 'hand', 'of', 'me', ',', 'that', 'it', 'requires', 'a', 'strong', 'moral', 'principle', 'to', 'prevent', 'me', 'from', 'deliberately', 'stepping', 'into', 'the', 'street', ',', 'and', 'methodically', 'knocking', 'people', \"'s\", 'hats', 'off', '—', 'then', ',', 'I', 'account', 'it', 'high', 'time', 'to', 'get', 'to', 'sea', 'as', 'soon', 'as', 'I', 'can', '.', 'This', 'is', 'my', 'substitute', 'for', 'pistol', 'and', 'ball', '.', 'With', 'a', 'philosophical', 'flourish', 'Cato', 'throws', 'himself', 'upon', 'his', 'sword', ';', 'I', 'quietly', 'take', 'to', 'the', 'ship', '.', 'There', 'is', 'nothing', 'surprising', 'in', 'this', '.', 'If', 'they', 'but', 'knew', 'it', ',', 'almost', 'all', 'men', 'in', 'their', 'degree', ',', 'some', 'time', 'or', 'other', ',', 'cherish', 'very', 'nearly', 'the', 'same', 'feelings', 'towards', 'the', 'ocean', 'with', 'me', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "number_of_thes = [token for token in tokens if re.search(\"^the$\",token)]\n",
    "print(number_of_thes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words, lammateization, stemming, tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [w for w in tokens if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'Ishmael', '.', 'Some', 'years', 'ago', '—', 'never', 'mind', 'long', 'precisely', '—', 'little', 'money', 'purse', ',', 'nothing', 'particular', 'interest', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'little', 'see', 'watery', 'part', 'world', '.', 'It', 'way', 'I', 'driving', 'spleen', ',', 'regulating', 'circulation', '.', 'Whenever', 'I', 'find', 'growing', 'grim', 'mouth', ';', 'whenever', 'damp', ',', 'drizzly', 'November', 'soul', ';', 'whenever', 'I', 'find', 'involuntarily', 'pausing', 'coffin', 'warehouses', ',', 'bringing', 'rear', 'every', 'funeral', 'I', 'meet', ';', 'especially', 'whenever', 'hypos', 'get', 'upper', 'hand', ',', 'requires', 'strong', 'moral', 'principle', 'prevent', 'deliberately', 'stepping', 'street', ',', 'methodically', 'knocking', 'people', \"'s\", 'hats', '—', ',', 'I', 'account', 'high', 'time', 'get', 'sea', 'soon', 'I', '.', 'This', 'substitute', 'pistol', 'ball', '.', 'With', 'philosophical', 'flourish', 'Cato', 'throws', 'upon', 'sword', ';', 'I', 'quietly', 'take', 'ship', '.', 'There', 'nothing', 'surprising', '.', 'If', 'knew', ',', 'almost', 'men', 'degree', ',', 'time', ',', 'cherish', 'nearly', 'feelings', 'towards', 'ocean', '.']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "philosophical\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('philosophical'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'Ishmael', '.', 'Some', 'year', 'ago', '—', 'never', 'mind', 'long', 'precisely', '—', 'little', 'money', 'purse', ',', 'nothing', 'particular', 'interest', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'little', 'see', 'watery', 'part', 'world', '.', 'It', 'way', 'I', 'driving', 'spleen', ',', 'regulating', 'circulation', '.', 'Whenever', 'I', 'find', 'growing', 'grim', 'mouth', ';', 'whenever', 'damp', ',', 'drizzly', 'November', 'soul', ';', 'whenever', 'I', 'find', 'involuntarily', 'pausing', 'coffin', 'warehouse', ',', 'bringing', 'rear', 'every', 'funeral', 'I', 'meet', ';', 'especially', 'whenever', 'hypo', 'get', 'upper', 'hand', ',', 'requires', 'strong', 'moral', 'principle', 'prevent', 'deliberately', 'stepping', 'street', ',', 'methodically', 'knocking', 'people', \"'s\", 'hat', '—', ',', 'I', 'account', 'high', 'time', 'get', 'sea', 'soon', 'I', '.', 'This', 'substitute', 'pistol', 'ball', '.', 'With', 'philosophical', 'flourish', 'Cato', 'throw', 'upon', 'sword', ';', 'I', 'quietly', 'take', 'ship', '.', 'There', 'nothing', 'surprising', '.', 'If', 'knew', ',', 'almost', 'men', 'degree', ',', 'time', ',', 'cherish', 'nearly', 'feeling', 'towards', 'ocean', '.']\n"
     ]
    }
   ],
   "source": [
    "lem_tokens = []\n",
    "for w in filtered_tokens:\n",
    "    lem_tokens.append(lemmatizer.lemmatize(w))\n",
    "print(lem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['call', 'ishmael', '.', 'some', 'year', 'ago', '—', 'never', 'mind', 'long', 'precis', '—', 'littl', 'money', 'purs', ',', 'noth', 'particular', 'interest', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'littl', 'see', 'wateri', 'part', 'world', '.', 'It', 'way', 'I', 'drive', 'spleen', ',', 'regul', 'circul', '.', 'whenev', 'I', 'find', 'grow', 'grim', 'mouth', ';', 'whenev', 'damp', ',', 'drizzli', 'novemb', 'soul', ';', 'whenev', 'I', 'find', 'involuntarili', 'paus', 'coffin', 'warehous', ',', 'bring', 'rear', 'everi', 'funer', 'I', 'meet', ';', 'especi', 'whenev', 'hypo', 'get', 'upper', 'hand', ',', 'requir', 'strong', 'moral', 'principl', 'prevent', 'deliber', 'step', 'street', ',', 'method', 'knock', 'peopl', \"'s\", 'hat', '—', ',', 'I', 'account', 'high', 'time', 'get', 'sea', 'soon', 'I', '.', 'thi', 'substitut', 'pistol', 'ball', '.', 'with', 'philosoph', 'flourish', 'cato', 'throw', 'upon', 'sword', ';', 'I', 'quietli', 'take', 'ship', '.', 'there', 'noth', 'surpris', '.', 'If', 'knew', ',', 'almost', 'men', 'degre', ',', 'time', ',', 'cherish', 'nearli', 'feel', 'toward', 'ocean', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "stem_tokens = []\n",
    "for w in lem_tokens:\n",
    "    stem_tokens.append(ps.stem(w))\n",
    "print(stem_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
